<!-- # 总线 -->
# Bus

<!-- 你已经设计了单周期处理器NPC, 也了解了设备如何工作.
不过我们之前是让仿真环境来提供设备的功能,
现在是时候从硬件上实现NPC与其他设备通信的功能了. -->

You've designed the single-cycle processor NPC, and you understand how the device works.
But we've let the simulation environment provide the functionality of the device
Now it's time to implement NPC - device communication in hardware.

<!-- 计算机中每个模块并非独立工作, 不同的模块之间需要进行数据交换:
CPU和内存控制器之间, 内存控制器和内存颗粒之间,
取指单元和译码单元之间等等,都需要通过一套约定的协议进行通信.
软件同样如此, 在我们使用的DiffTest中, NEMU需要与Spike通信, NPC也需要与NEMU通信才能实现相应的功能. -->

In a computer, each module does not work independently; data exchange is required between different modules: between the CPU and the memory controller, between the memory controller and the memory chips, between the instruction fetch unit and the decode unit, etc. Communication between these modules must be conducted through a set of agreed-upon protocols. The same is true for software. In the DiffTest tool that we use, NEMU needs to communicate with Spike, and NPC also needs to communicate with NEMU to implement the corresponding functions.

<!-- 从广义上来说, 总线其实就是一个通信系统, 用来在不同的模块之间进行数据传输.
我们接下来将聚焦于硬件, 介绍狭义的总线, 即硬件模块间的通信协议. -->

In a broad sense, a bus is essentially a communication system used for data transfer between different modules. Next, we will focus on hardware and introduce the narrow sense of the bus, which refers to the communication protocols between hardware modules.

<!-- ## 总线 - 硬件模块间的通信协议 -->
# Bus - Communication Protocols Between Hardware Modules


<!-- 我们先从处理器内部的模块通信开始, 理解总线协议的一般构成. -->

We will start with communication between modules inside the processor to understand the general composition of bus protocols.

<!-- ### 最简单的总线 -->
### The Simplest Bus

<!-- NPC中包含取指单元IFU和译码单元IDU, 两个单元间需要进行通信, 将指令由IFU传递给IDU. -->

In the NPC, there is an Instruction Fetch Unit (IFU) and an Instruction Decode Unit (IDU), and these two units need to communicate to transfer instructions from the IFU to the IDU.

```scala
+-----+           +-----+
| IFU | inst ---> | IDU |
+-----+           +-----+
```scala

<!-- 在这个简单的场景其实就隐含了总线协议:
一般称主动发起通信的模块为master(主设备), 称响应通信的模块为slave(从设备).
在上述的简单交互场景中, 作为master的IFU向作为slave的IDU发送信息, 发送的信息为当前的指令.
作为单周期处理器, 显然, 二者的通信实际上隐含了如下约定:
* 每个周期master都向slave发送有效信息
* master一旦发送有效信息, slave能够立刻收到 -->

In this simple scenario, there is an implied bus protocol: the module that initiates communication is generally called the master, and the module that responds to communication is called the slave. In the simple interaction scenario above, the IFU, as the master, sends information to the IDU, which is the slave, with the information being the current instruction. As a single-cycle processor, obviously, their communication actually implies the following agreement:
* Every cycle, the master sends valid information to the slave.
* Once the master sends valid information, the slave can receive it immediately.

<!-- ### 异步总线 -->

### Asynchronous Bus

<!-- 但如果IFU不能保证每个周期都能取到指令, 此时IDU需要等待IFU完成取指.
这种情况下, 就需要在通信内容中增加一个有效信号`valid`, 来指示IFU何时向IDU发送有效的指令.
通信协议也需要更新如下:
* 只有在`valid`信号有效时才认为信息有效
* master一旦发送有效信息, slave能够立刻收到 -->

However, if the IFU cannot guarantee to fetch an instruction every cycle, then the IDU needs to wait for the IFU to complete the fetch. In this case, it is necessary to add a valid signal to the communication content to indicate when the IFU sends a valid instruction to the IDU. The communication protocol also needs to be updated as follows:
* Information is considered valid only when the valid signal is valid.
* Once the master sends valid information, it is considered received by the slave only when the ready signal is valid.

```scala
+-----+ inst  ---> +-----+
| IFU | valid ---> | IDU |
+-----+            +-----+
```scala

<!-- 那么, 如何避免让IDU执行无效指令呢?
回想一下处理器的状态机模型, 我们只要在指令无效时让处理器的状态保持不变即可.
在电路层次, 状态就是时序逻辑元件, 因此, 只需在指令无效时将时序逻辑元件的写使能置为无效即可. -->

So, how do we prevent the IDU from executing invalid instructions? Recalling the state machine model of the processor, we just need to keep the processor's state unchanged when the instruction is invalid. At the circuit level, the state is the sequential logic components, therefore, we just need to set the write enable of the sequential logic components to invalid when the instruction is invalid.

<!-- 再进一步, 假设有些指令的译码操作过于复杂, IDU需要多个周期才能译码一条指令.
在这种假设下, 当IFU成功取到一条指令时, IDU可能还未完成上条指令的译码,
这时IFU应该先等待IDU完成当前的译码工作, 再向IDU发送下一条指令.
为了实现让IFU等待的功能, 就需要在通信内容中增加一个就绪信号`ready`, 来指示IDU何时能接收下一条指令.
通信协议也需要更新如下:
* 只有在`valid`信号有效时才认为信息有效
* master发送的信息, 只有在`ready`信号有效时才认为slave收到 -->

Further, suppose some instructions are too complex to decode, and the IDU needs multiple cycles to decode a single instruction. Under this assumption, when the IFU successfully fetches an instruction, the IDU may not have finished decoding the previous instruction. At this time, the IFU should wait for the IDU to complete the current decoding work before sending the next instruction to the IDU. To implement the function of making the IFU wait, it is necessary to add a `ready` signal to the communication content to indicate when the IDU can receive the next instruction. The communication protocol also needs to be updated as follows:
* Information is considered valid only when the `valid` signal is set.
* The information sent by the master is considered received by the slave only when the `ready` signal is set.

```scala
+-----+ inst  ---> +-----+
| IFU | valid ---> | IDU |
+-----+ <--- ready +-----+
```scala

<!-- 这实际上就是异步总线, 两个模块之间何时发生通信是无法提前预知的, 只有在`valid`和`ready`均有效时才发生.
`valid`和`ready`均有效, 也称为"握手", 表示master和slave对信息的成功传递达成共识.
显然, 这种通信协议更加灵活, master和slave将根据自身的工作情况决定何时发送或接收消息.
在`valid`信号有效, 而`ready`信号无效时, IFU需要等待IDU就绪, 此时IFU应暂存将要发送的信息, 以防止信息丢失. -->

This actually refers to an asynchronous bus, where it is unpredictable when communication between the two modules will occur; it only happens when both `valid` and `ready` signals are set. Both signals being set, also known as a "handshake," indicates that the master and slave have reached a consensus on the successful transmission of information. Clearly, this communication protocol is more flexible, allowing the master and slave to decide when to send or receive messages based on their own work situations. When the `valid` signal is set and the `ready` signal is not set, the IFU needs to wait for the IDU to be ready. At this time, the IFU should temporarily store the information to be sent to prevent loss of information.

<!-- ### 异步总线的RTL实现 -->

### The RTL (Register Transfer Level) implementation of an asynchronous bus

<!-- 异步总线通过握手协议确定何时通信, 在RTL层次, 它主要由接口信号和通信逻辑这两部分组成.

接口信号即需要在模块间传递的信号, 如上述例子中的`inst`, `valid`和`ready`信号.
Chisel提供了Decoupled模板, 自带`valid`和`ready`, 通过元编程可以轻松实现异步总线接口: -->

The asynchronous bus determines when to communicate through a handshake protocol. At the RTL level, it mainly consists of two parts: interface signals and communication logic.

Interface signals are the signals that need to be transmitted between modules, such as the `inst`, `valid`, and `ready` signals in the example above. Chisel provides a Decoupled template, which comes with `valid` and `ready`, and asynchronous bus interfaces can be easily implemented through meta-programming.

```scalascala
class Message extends Bundle {
  val inst = Output(UInt(32.W))
}

class IFU extends Module {
  val io = IO(new Bundle { val out = Decoupled(new Message) })
  // ...
}
class IDU extends Module {
  val io = IO(new Bundle { val in = Filpped(Decoupled(new Message)) })
  // ...
}
```scala

<!-- 需要传递更多信息时, 也能很方便地增加信号, 这就是抽象带来的好处! -->

When more information needs to be transmitted, it is also very convenient to add signals. This is the benefit brought by abstraction!

```scaladiff
 class Message extends Bundle {
   val inst = Output(UInt(32.W))
+  val pc = Output(UInt(32.W))
 }
```scala

<!-- 接下来是通信逻辑, 也即如何用电路实现上述总线协议.
协议是master和slave双方之间的约定, 而在电路上真正需要实现的, 是双方在遵守这一约定之下的行为.
也即, 双方根据握手信号的不同情况, 进入不同的状态, 从而采取不同的操作. 这就是状态机!
对于master而言, 我们可以很容易画出它的状态转移图. -->

Next is the communication logic, which is how to implement the bus protocol with circuits. The protocol is an agreement between the master and the slave, and what really needs to be implemented in the circuit is the behavior of both parties while adhering to this agreement. That is, both parties enter different states based on the different conditions of the handshake signals, thereby taking different actions. This is the state machine! For the master, we can easily draw its state transition diagram.

```scala
   +-+ valid = 0
   | v         valid = 1
1. idle ----------------> 2. wait_ready <-+
   ^                          |      |    | ready = 0
   +--------------------------+      +----+
```scala

<!-- 具体地:
1. 一开始处于空闲状态`idle`, 将`valid`置为无效
   1. 如果不需要发送消息, 则一直处于`idle`状态
   2. 如果需要发送消息, 则进入`wait_ready`状态, 等待slave就绪
1. 如果需要发送消息, 则将`valid`置为有效, 并进入`wait_ready`状态, 等待slave就绪
   1. 如果`ready`信号有效, 则握手成功, 返回`idle`状态
   1. 如果`ready`信号无效, 则继续处于`wait_ready`状态等待

根据状态转移图, 我们就可以很容易写出相应的RTL代码了.
这里也给出了一段简单的Chisel代码供大家参考: -->

Specifically:
1. Initially in the idle state, unset `valid` signal
   1. If there is no need to send a message, remain in the idle state
   2. If a message needs to be sent, transition to the `wait_ready` state and wait for the slave to be ready
2. In the `wait_ready` state, set `valid` signal, while checking the slave's `ready` signal
   1. If the `ready` signal is set, the handshake is successful, return to the idle state
   2. If the `ready` signal is unset, continue to stay in the `wait_ready` state and wait

With the state transition diagram, we can easily write the corresponding RTL. 
Here is a simple Chisel code snippet for reference:

<!-- ```scala
class IFU extends Module {
  val io = IO(new Bundle { val out = Decoupled(new Message) })

  val s_idle :: s_wait_ready :: Nil = Enum(2)
  val state = RegInit(s_idle)
  state := MuxLookup(state, s_idle)(List(
    s_idle       -> Mux(io.out.valid, s_wait_ready, s_idle),
    s_wait_ready -> Mux(io.out.ready, s_idle, s_wait_ready)
  ))

  io.out.valid := 有指令需要发送
  // ...
}
```scala -->

```scala
class IFU extends Module {
  val io = IO(new Bundle { val out = Decoupled(new Message) })

  val s_idle :: s_wait_ready :: Nil = Enum(2)
  val state = RegInit(s_idle)
  state := MuxLookup(state, s_idle)(List(
    s_idle       -> Mux(io.out.valid, s_wait_ready, s_idle),
    s_wait_ready -> Mux(io.out.ready, s_idle, s_wait_ready)
  ))

  io.out.valid := instruction need to be send
  // ...
}
```scala

<!-- > #### question::用RTL实现IDU的通信
> 理解IFU通信的实现过程之后, 尝试分析并画出IDU的状态转移图, 并写出IDU通信的RTL代码.
> 这只是一个总线的练习, 目前你不必修改NPC中IDU的代码. -->

> #### question::Implementing IDU Communication in RTL
> After understanding the implementation process of IFU communication, try to analyze and draw the state transition diagram of IDU, and write the RTL code for IDU communication. This is just an exercise about bus, you don't need to modify the IDU code in NPC at the moment.

<!-- 当我们完整实现IFU和IDU的通信逻辑后, 上述总线协议也就实现好了. -->

When we fully implement the communication logic of both IFU and IDU, the above bus protocol will also be effectively implemented.

<!-- ## 总线视角下的处理器设计 -->

## Processor Design from a Bus Perspective

<!-- 我们可以从总线角度来重新看处理器设计本身.
假设处理器包含4个模块, 各模块之间需要进行通信:
IFU向IDU发送指令, IDU将译码结果发送给EXU, EXU将计算结果发送给WBU. -->

We can reconsider the processor design itself from a bus perspective.
Assuming the processor consists of 4 modules that need to communicate with each other:
IFU sends instructions to IDU, IDU sends the decoded results to EXU, EXU sends the computation results to WBU.

```scala
+-----+ inst  ---> +-----+  ...  ---> +-----+  ...  ---> +-----+
| IFU | valid ---> | IDU | valid ---> | EXU | valid ---> | WBU |
+-----+ <--- ready +-----+ <--- ready +-----+ <--- ready +-----+
```scala

<!-- 在这个视角下, 不同微结构的处理器实际上只是模块间的通信协议不同:
* 对于单周期处理器, 相当于每个周期上游发送的消息都有效, 同时下游处于就绪状态来接收新消息 
* 对于多周期处理器, 上游模块空闲时消息无效, 下游模块忙碌时不接收新消息; IFU收到WBU的完成信号后再取下一条指令
  * 和传统课本不同, 这是一个基于消息控制的分布式多周期处理器,
    其中的"分布式"体现在: 两个模块能否互相通信只取决于二者的状态, 和其他模块无关 -->

From this perspective, different microarchitectures of processors essentially represent varying communication protocols between modules:
* For a single-cycle processor, it is bascially every message sent by the upstream being valid each cycle, while the downstream remains ready to receive new messages.
* For a multi-cycle processor, messages are invalid when the upstream module is idle, and new messages are not accepted when the downstream module is busy. The IFU fetches the next instruction only after receiving the completion signal from WBU.
  * Unlike traditional textbooks, this is a message-controlled distributed multi-cycle processor,
    where the "distributed" aspect lies in: whether two modules can communicate with each other solely depends on their states, independent of other modules.

<!-- > #### info::课本上的多周期处理器
> 在多周期处理器中, 一条指令被划分为不同的阶段, 并在不同的周期中执行, 因此每条指令都需要花费多个时钟周期:
> * 在第1个周期, IFU取指令并将指令传递到IDU
> * 在第2个周期, IDU将译码结果传递给EXU
> * 在第3个周期, EXU将计算结果传递给WBU
> * 在第4个周期, WBU将结果写回寄存器堆
> * 在下一个周期, IFU再取出下一条指令... -->

> #### info::Multi-cycle Processor in Textbooks
> In a multi-cycle processor, an instruction is divided into different stages and executed in different cycles, hence each instruction takes multiple clock cycles to complete:
> * In the 1st cycle, IFU fetches the instruction and passes it to IDU
> * In the 2nd cycle, IDU sends the decoded result to EXU
> * In the 3rd cycle, EXU passes the computation result to WBU
> * In the 4th cycle, WBU writes back the result to the register file
> * In the next cycle, IFU fetches the next instruction...

<!-- * 对于流水线处理器, 则可以让IFU一直取指, 同时每个模块只要有消息处理完成, 就在每个周期都尝试向下游发送消息
* 对于乱序执行处理器, 则可以看成在流水线的基础上进行很小的扩展:
  每一个下游模块中都有一个队列, 上游模块只需把消息发送到队列中, 就可以不用关心下游队列的状态继续工作 -->

* For a pipelined processor, IFU can continuously fetch instructions, and each module attempts to send messages downstream every cycle as soon as it completes processing any message.
* For an out-of-order execution processor, it can be seen as a minor extension of the pipeline:
  Each downstream module has a queue, and the upstream module only needs to send messages to the queue without worrying about the state of the downstream queue.

<!-- 通常, 集中式控制需要有一个全局的控制器, 负责收集所有模块的状态, 再根据这些状态来控制各个模块的下一步工作.
传统课本中介绍的多周期处理器, 通常是一个基于大状态机的集中式多周期处理器.
它通过全局的大状态机来收集每个模块的状态, 从而控制每个模块之间的通信, 并确定下一个状态应该是什么.
例如在当前周期IFU取指完成, 那下一个周期就应该进入译码状态, 并控制IDU进行译码.  -->

Usually, centralized control requires a global controller responsible for collecting the states of all modules and then using these states to control the next steps of each module. The multi-cycle processor typically introduced in traditional textbooks is often a centralized multi-cycle processor based on a large state machine. It collects the states of each module through a global state machine to control communication between each module and determine what the next state should be. For example, if instruction fetching is completed in the current cycle, then in the next cycle, it should enter the decoding state and control IDU to perform decoding.

```scala
                   +--------------+
   +-------------> |  Controller  | <--------------+
   |               +--------------+                |
   |                ^            ^                 |
   v                v            v                 v
+-----+  inst   +-----+   ...   +-----+   ...   +-----+
| IFU | ------> | IDU | ------> | EXU | ------> | WBU |
+-----+         +-----+         +-----+         +-----+
```scala

<!-- 课本上通常只通过少数几条指令来介绍多周期状态机的基本原理, 这时问题并不大.
但集中式控制的可扩展性比较低, 随着模块的数量还有复杂度的提升, 控制器的设计会越来越复杂:
* 随着指令数量增加, 指令的类别也会增加, 这个集中式状态机需要考虑每一类指令执行的所有阶段
* 如果想在这个处理器中插入一个新阶段, 就需要重新设计控制器
* 在真实的处理器中, 每个模块的工作时间可能各不相同
  * IFU取指可能存在延迟
  * 而IDU可能只需要一个周期就能完成译码
  * 在EXU中, 不同指令的执行时间可能各不相同
    * RVI中的整数运算指令通常只需要一个周期就能完成计算
    * 除法通常需要执行很久
    * 乘法可能更快一些, 但可能也需要数个周期
    * 访存指令需要等待的时间无法提前预知
* 一些指令的执行可能会触发异常, 中断也可能会随时到来 -->

In textbooks, usually only a few instructions are used to introduce the basic principles of multi-cycle state machines, which is not a big issue per say. However, the scalability of centralized control is relatively low. As the number of modules and complexity increase, the design of the controller becomes more complex:
* With an increase in the number of instructions, the types of instructions also increase. The centralized state machine needs to consider all stages of execution for each type of instruction.
* Inserting a new stage in this processor would require a redesign of the controller.
* In real processors, the working time of each module may vary:
  * Instruction fetching in IFU may have delays.
  * IDU may complete decoding in just one cycle.
  * In EXU, different instructions may have varying execution times:
    * Integer arithmetic instructions in RVI typically complete calculations in one cycle.
    * Division usually takes a long time.
    * Multiplication might be faster but could still take several cycles.
    * Memory access instructions have unpredictable wait times.
* The execution of some instructions may trigger exceptions, and interrupts can arrive at any time.

<!-- 在这种复杂场景中, 需要考虑每个模块不同状态的组合, 统一的决策是很困难的.

而上文提到的分布式控制中, 每个模块的行为只取决于自身和下游模块的状态, 每个模块可以独立工作.
例如在乱序执行处理器中, 上游模块可以一直工作, 直到下游模块中的队列满为止.
我们可以从总线角度来重新审视处理器设计本身.
因此, 分布式控制具有更好的可扩展性.

采用这种基于握手的分布式控制, 可以统一不同微结构的处理器的设计.
此外, 乱序执行处理器天生就是分布式控制的, 这是因为乱序执行处理器中的模块和每个模块的状态都非常多,
且随时可能到来一些不同的事件(如中断到来, 流水线阻塞等),
如果采用集中式控制, 我们几乎无法保证控制器能在每个模块发生不同事件时都做出正确的决策.  -->

In such complex scenarios, considering the combination of different states for each module, making unified decisions becomes very challenging.

In the distributed control mentioned earlier, where each module's behavior depends only on its own state and the state of downstream modules, each module can work independently. For example, in an out-of-order execution processor, the upstream module can continue working until the downstream queue is full.

In distributed control, it is very easy to insert a new module; you only need to modify the implementation of the state machines of its upstream and downstream modules. Therefore, distributed control offers better scalability.

By adopting this handshake-based distributed control, the design of different microarchitectures of processors can be unified. Furthermore, out-of-order execution processors are inherently distributed control systems because they have many modules and states for each module, and various events can occur at any time (such as interrupts or pipeline stalls). If centralized control were used, it would be nearly impossible to ensure that the controller makes correct decisions for each module when different events occur.

<!-- > #### comment::总线在系统设计中的好处
> 你应该可以体会到总线在系统设计中的好处之一:
> 通过划分模块并在模块之间进行通信, 降低整个系统的设计和维护的复杂度.
> 集中式控制器需要和每一个模块进行通信, 因此它的设计和维护是最困难的;
> 通过总线协议将全局通信分解到上下游模块之间, 就消除了集中式控制器,
> 从而降低了整个处理器的设计复杂度.
>
> 事实上, 计算机领域中的很多例子都是通过消息通信降低系统的复杂度,
> 例如操作系统中的微内核, 分布式系统中的MPI编程框架,
> 软件架构中的C/S模型(客户端-服务器模型), 甚至整个互联网都是通过网络包进行通信.
>
> 处理器设计的对象固然是硬件, 但设计模式并不仅仅是一个硬件问题,
> 我们还是可以从软件领域借鉴一些有用的经验帮助我们把处理器设计这件事做得更好. -->

> #### comment::Benefits of Buses in System Design
> You should be able to appreciate one of the benefits of buses in system design:
> By dividing modules and enabling communication between them, the overall complexity of system design and maintenance is reduced.
> A centralized controller needs to communicate with every module, making its design and maintenance the most challenging;
> By decomposing global communication into interactions between upstream and downstream modules through bus protocols, the need for a centralized controller is eliminated,
> thereby reducing the complexity of the entire processor design.
>
> In fact, many examples in the field of computing use message passing to reduce system complexity,
> such as microkernels in operating systems, MPI programming frameworks in distributed systems,
> client-server models in software architecture, and even the entire internet communicates through network packets.
>
> While processor design deals with hardware, design patterns are not solely a hardware issue,
> and we can still draw useful experiences from the software domain to help improve processor design.

利用Chisel中的函数抽象和元编程功能, 我们可以将不同微结构处理器的设计模式统一起来,
并且很容易对处理器微结构进行"升级".

```scalascala
class NPC extends Module {
  val io = // ...

  val ifu = Module(new IFU)
  val idu = Module(new IDU)
  val exu = Module(new EXU)
  val wbu = Module(new WBU)

  StageConnect(ifu.io.out, idu.io.in)
  StageConnect(idu.io.out, exu.io.in)
  StageConnect(exu.io.out, wbu.io.in)
  // ...
}

object StageConnect {
  def apply[T <: Data](left: DecoupledIO[T], right: DecoupledIO[T]) = {
    val arch = "single"
    // 为展示抽象的思想, 此处代码省略了若干细节
    if      (arch == "single")   { right.bits := left.bits }
    else if (arch == "multi")    { right <> left }
    else if (arch == "pipeline") { right <> RegEnable(left, left.fire) }
    else if (arch == "ooo")      { right <> Queue(left, 16) }
  }
}
```scala

在分布式控制中, 能够非常容易插入一个新模块, 只需要修改该模块的上下游模块的接口实现即可.
> #### option::重构NPC
> 尽管这并不是强制性的, 但如果你使用Chisel开发, 我们强烈建议你进行重构,
> 这也是为接下来接入SoC, 以及将来实现流水线提前做好准备.
>
> 如果你使用Verilog开发, 你可能会感到重构工作有一些繁琐.
> 不过, 我们想强调的是, 设计模式和RTL实现是不同的层面,
> 尽管你可能会遇到一些困难, 但我们还是鼓励你思考如何通过Verilog实现上述正确的设计模式.

## 系统总线

除了上文介绍的处理器内各模块的连接之外, 处理器如何连接到存储器和设备也是至关重要的,
毕竟真实的处理器无法脱离存储器和外设进行工作.
连接处理器和存储器以及设备之间的总线通常称为系统总线.
下面我们以处理器和存储器之间的连接为例, 介绍系统总线应该如何设计.

### 访问只读存储器

由于从存储器中读出数据是最基本的需要, 我们首先考虑处理器如何通过系统总线完成读操作.
假设处理器规格固定为Nx32, 即存储器包含N个字, 每个字为32位.
同时假设该存储器的读延迟固定为1周期, 这实际上是一种同步存储器,
即从收到读请求到返回数据之间的延迟是固定的, SRAM的访问特性正是如此.
事实上, NPC仿真环境提供的`pmem_read()`没有读延迟, 收到读请求的当前周期就可以返回读数据,
但它只是用于方便我们实现单周期处理器, 实际上并不存在这样的存储器器件.

如果不考虑写操作, 我们只需要一个只读存储器(ROM, Read-Only Memory)即可.
为了从ROM中读出数据, 相应的总线只需要两个信号, 分别为地址和数据, 二者的位宽分别为log2(N)和32.

```scala
+-----+ raddr[log2(N)-1:0] ---> +-----+
| CPU | <---        rdata[31:0] | MEM |
+-----+                         +-----+
```scala

其通信协议为:
* master(CPU)向slave(MEM)发送读地址`raddr`
* 下个周期slave向master回复数据`rdata`
* 上述行为每周期都发生

> #### todo::评估单周期NPC的主频和程序性能
> 在进一步修改NPC之前, 尝试通过你在预学习阶段中使用的`yosys-sta`项目来评估当前NPC的主频.
> 不过在评估之前, 你需要进行以下工作:
> 1. 先运行microbench的train规模测试, 记录其运行结束所需的周期数
> 1. 在RTL中注释通过DPI-C调用`pmem_read()`和`pmem_write()`的代码,
>    然后为取指和访存各自实例化一个存储器.
>    为了保持单周期的特性, 我们需要实例化的存储器需要当前周期就能返回读数据,
>    因此我们可以像寄存器堆那样通过触发器实现它.
>    如果你使用Verilog, 可以直接实例化`RegisterFile`模块, 当然你需要把端口正确连上.
>    为了统一测试结果, 我们约定实例化的存储器大小为256x32b, 即1KB,
>    共实例化两个这样的存储器, 总大小为2KB.
>
> 我们之所以这样修改, 是因为单周期NPC要求每个周期都完成一条指令完整的生命周期,
> 因此无法连接任何现实中的存储器, 只能连带两个类似寄存器堆的存储器一同评估主频.
> 修改后, 你就可以评估单周期NPC的主频了.
>
> 根据评估的主频和刚才记录的microbench执行的周期数,
> 就可以估算出将来NPC运行microbench需要多久了.
> 注意这并非仿真的耗时, 而是假设NPC在上述主频下运行程序的时间.
> 例如, yzh某个版本的NPC在`yosys-sta`项目默认提供的nangate45工艺下主频为51.491MHz,
> 因此可以算出microbench需要运行3.870s, 但仿真花费了19.148s.
>
> 当然, 这个估算结果其实并不准确, 而且还可以说是非常乐观的:
> * 这个单周期NPC距离可流片的配置还差很远, 例如我们刚才修改存储器的时候, 其实把I/O相关的部分都忽略了
> * 上述主频是综合后的主频, 布局布线之后引入的线延迟会进一步把主频拉低
> * 取指单元对应的存储器因为没有写操作, 被yosys优化掉了
> * 访存单元对应的存储器其实也远远装不下microbench.
>   要成功把train规模的测试运行起来, 数据需要占用1MB内存.
>   这个大小都已经远远超过实际处理器芯片设计中可以容纳的触发器数量了,
>   先不考虑EDA工具的处理时间, 光是在芯片上摆满这么多触发器,
>   从占用面积来估算线延迟就已经大得不得了了.
>
> 所以, 这个评估结果的参考意义其实很小, 就当作是给后续的评估练练手吧.

<!-- -->
> #### todo::将IFU访问的存储器改造成SRAM
> 1. 用RTL为IFU编写一个SRAM模块, 地址位宽为32bit, 数据位宽为32bit
> 1. 收到读请求后, SRAM模块通过DPI-C调用`pmem_read()`读出数据,
>    并延迟1周期返回读出的数据, 来实现一个更真实的存储器
>
> 不过由于这个SRAM需要经过1周期才能拿到读出的数据,
> 这时候NPC已经不是一个严格意义上的单周期处理器了, 而是一个简单的多周期处理器:
> 1. 在第1个周期, IFU发出取指请求
> 1. 在第2个周期, IFU拿到指令, 并交给后续的模块译码并执行
>
> 如果你按照前文的建议重构了NPC, 你会发现将NPC改造成多周期处理器并不难实现.

<!-- -->
> #### option::让DiffTest适配多周期处理器
> 修改成多周期处理器后, NPC就并非每个周期都执行一条指令了.
> 为了让DiffTest机制可以正确工作, 你需要对检查的时机稍作调整.
> 为此, 你可能需要从仿真环境中读取RTL的一些状态,
> 来帮助你判断应该什么时候进行DiffTest的检查.

### 访问可读可写存储器

如果要支持写操作, 就需要在总线中添加新的信号:
* 首先自然需要写地址`waddr`和写数据`wdata`
* 由于写操作并非每个周期都发生, 因此还需要添加写使能信号`wen`
  * 虽然读操作也并非每个周期都发生, 例如对于改成多周期处理器的NPC, 第2个周期并不需要取指,
    但由于读操作不会改变电路状态, 因此理论上读使能并非必须
  * 不过实际中一般还是有读使能`ren`, 如果没有读请求, 存储器就无需进行读操作, 从而节省能耗
* 写操作可能只写入一个字当中的若干字节(例如`sb`指令只写入1字节),
  因此还需要添加写掩码信号`wmask`, 用于指定写入数据中的哪些字节

```scala
+-----+ raddr[log2(N)-1:0] ---> +-----+
|     | ren                ---> |     |
|     | <---        rdata[31:0] |     |
|     | waddr[log2(N)-1:0] ---> |     |
| CPU | wdata[31:0]        ---> | MEM |
|     | wen                ---> |     |
|     | wmask[3:0]         ---> |     |
+-----+                         +-----+
```scala

同时, 通信协议需要增加写操作行为的定义, 我们用伪代码来表示:
```scalac
if (wen) {
  // wmask_full为wmask按比特展开的结果
  M[waddr] = (wdata & wmask_full) | M[waddr] & ~wmask_full;
}
```scala

> #### todo::将LSU(访存单元)访问的存储器改造成SRAM
> 1. 用RTL为LSU编写一个SRAM模块, 地址位宽为32bit, 数据位宽为32bit
> 1. 收到读写请求后, 通过DPI-C调用`pmem_read()`/`pmem_write()`,
>    并延迟1周期返回读出的数据
>    * 此时可以保留`pmem_read()`/`pmem_write()`中的设备访问功能,
>       我们将在后续讲义中介绍如何通过总线访问外设
>
> 实现后, 对于`load`指令, NPC需要3个周期才能完成:
> 1. 在第1个周期, IFU发出取指请求
> 1. 在第2个周期, IFU拿到指令, 并交给后续的模块译码,
>    发现是`load`指令后, 则通过LSU发出访存请求
> 1. 在第3个周期, LSU拿到数据, 并交给WBU写回寄存器

<!-- -->
> #### comment::同时读写同一个地址 - RTFM
> 如果同时读写同一个地址, 存储器究竟读出哪个数据呢?
> 事实上, 具体的行为需要RTFM: 器件的手册规定了该操作的行为, 在部分器件中, 读结果是未定义的.
> SRAM和FPGA中的Block RAM大都是这种特性.
>
> 因此, master端尽量不要同时读写同一个地址.
> 如果实在无法避免, 可以在master端加入检测逻辑, 在检测到读写同相同地址时,
> 可以延迟写操作, 先读出旧数据; 或者延迟读操作, 先写入数据, 再读出写入后的新数据.
> 这样, 至少可以保证读结果是有定义的.
>
> 不过, 当前NPC的IFU只会发出读请求, 而LSU则不会同时发出读请求和写请求
> (取决于正在执行的是`load`指令还是`store`指令), 因此当前你无需在NPC中考虑这个问题.

### 更普遍的存储器

> 尝试采用上面的总线思想, 重构NPC.
因为它能够使用与处理器制造相同的工艺进行生产, 但SRAM的价格十分昂贵.
为了实现更低成本的存储器, 通常会采用其他存储密度更大的工艺来制造存储器, 例如DRAM.
但由于电气特性, 这些存储器的读延迟通常大于处理器的1周期.

这时处理器不能一直发送读请求, 否则由于处理器的请求速率大于存储器的服务速率,
导致存储器会一直被无用的请求占据, 严重降低整个系统的工作效率.
为了解决这个问题, master需要告诉slave何时发送有效的请求, 同时也需要识别slave何时能接收请求.
这可以通过之前介绍的握手实现: 只要在master和slave之间的读协议添加一对握手信号即可,
也即, 添加`rvalid`指示处理器发送的读请求`raddr`有效, 添加`rready`指示存储器可以接收读请求.
这里的`rvalid`实际上也充当了读使能`ren`的作用.

```scala
+-----+ raddr[log2(N)-1:0] ---> +-----+
|     | rvalid             ---> |     |
|     | <---             rready |     |
|     | <---        rdata[31:0] |     |
| CPU | waddr[log2(N)-1:0] ---> | MEM |
|     | wdata[31:0]        ---> |     |
|     | wen                ---> |     |
|     | wmask[3:0]         ---> |     |
+-----+                         +-----+
```scala

事实上, 存储器何时完成读操作也是无法提前得知的,
例如DRAM会周期性地对存储单元的电容进行充电刷新, 如果此时收到读请求, 将会在充电刷新结束之后才会真正读出数据.
另一方面, 处理器也可能因为上一次读出的数据还没用完, 而没有准备好接收存储器返回的数据.
这些问题也都需要通过握手信号来解决: 添加`rvalid`信号表示存储器已经读出有效的数据,
添加`rready`信号表示处理器可以接收存储器返回的数据.
不过这两个信号和上文读请求的握手信号重名了,
事实上, 读延迟为1周期的特性通常只有SRAM能够满足,

```scala
+-----+ araddr[log2(N)-1:0] ---> +-----+
|     | arvalid             ---> |     |
|     | <---             arready |     |
|     | <---         rdata[31:0] |     |
|     | <---              rvalid |     |
| CPU | rready              ---> | MEM |
|     | waddr[log2(N)-1:0]  ---> |     |
|     | wdata[31:0]         ---> |     |
|     | wen                 ---> |     |
|     | wmask[3:0]          ---> |     |
+-----+                          +-----+
```scala

因此, 在一次读事务的完成过程中, master和slave都需要经历两次握手:
master先等`arready`, 确保slave接收读地址后, 再等`rvalid`接收读数据;
而slave则先等`arvalid`接收读地址, 再等`rready`, 确保master接收读数据.
当然, 在RTL实现层面, 这些都是状态机.

同样地, 写事务也需要握手, 因此需要添加`wvalid`和`wready`信号:

```scala
+-----+ araddr[log2(N)-1:0] ---> +-----+
|     | arvalid             ---> |     |
|     | <---             arready |     |
|     | <---         rdata[31:0] |     |
|     | <---              rvalid |     |
| CPU | rready              ---> | MEM |
|     | waddr[log2(N)-1:0]  ---> |     |
|     | wdata[31:0]         ---> |     |
|     | wmask[3:0]          ---> |     |
|     | wvalid              ---> |     |
+-----+ <---              wready +-----+
```scala

> #### info::握手信号的微结构设计意义 - 解耦
为了区分, 我们为读地址相关的握手信号添加前缀`a`表示地址, 即`arvalid`和`arready`.
> 例如, DRAM何时读出数据受很多因素的影响, 包括刷新时机, DRAM控制器的请求调度,
> DRAM颗粒中的row buffer是否命中, 甚至颗粒的电气特性等.
> 而CPU何时发送请求并接收数据, 同样也受很多因素的影响,
> 包括程序何时执行访存指令, 流水线的堵塞情况, 缓存的状态等.
> 如果通信的时候其中一方要考虑另一方的这些情况, 这样的设计是不可能实现的:
> 我们没有办法知道另一方处于什么状态.
>
> 握手信号成功地把双方的状态解耦开来,
> 有了握手信号之后, 双方都无需关心对方模块的状态, 只需要等待握手即可.
> 因此, 只要模块遵循同一套总线协议, 接入总线后就可以顺利工作.

### 错误处理和异常

在部分情况下, 存储器处理读写事务的时候可能会发生错误,
例如读写地址超过了存储区间的范围, 或者通过校验码发现读写的存储单元发生损坏.
在这些情况下, slave通常应该告诉master发生了错误, 让master决定如何处理.
因此, 我们需要在存储器返回读出数据时额外传输一个`rresp`信号,
来指示读操作是否成功, 若不成功, 读数据`rdata`是无效的.
同理, 存储器在处理写操作后也需要返回一个写回复信号`bresp`(这里的`b`表示`backward`),
当然, 这个信号也需要握手.

```scala
+-----+ araddr[log2(N)-1:0] ---> +-----+
|     | arvalid             ---> |     |
|     | <---             arready |     |
|     | <---         rdata[31:0] |     |
|     | <---          rresp[1:0] |     |
|     | <---              rvalid |     |
|     | rready              ---> |     |
| CPU | waddr[log2(N)-1:0]  ---> | MEM |
|     | wdata[31:0]         ---> |     |
|     | wmask[3:0]          ---> |     |
|     | wvalid              ---> |     |
|     | <---              wready |     |
|     | <---          bresp[1:0] |     |
|     | <---              bvalid |     |
+-----+ bready              ---> +-----+
```scala

在处理器中, 如果读写操作出错, 可以进一步抛出异常, 通知软件进行处理.
例如, RISC-V设置了3种`Access Fault`异常, 分别代表在存储器中取指令, 读数据, 写数据时出错.
这样, 存储器内部的错误就可以通过总线协议传递到处理器,
再通过处理器的异常处理机制告知软件了.

## 业界中广泛使用的总线 - AXI协议家族

我们对上文的总线协议稍作变换:
1. 将写地址和写数据分开, 写地址采用`aw`前缀, 写数据采用`w`前缀
1. 将`wmask`改名为`wstrb`, 并将信号按功能分成5组

```scala
araddr  --->               araddr  --->              araddr  ---> -+
arvalid --->               arvalid --->              arvalid --->  AR
<--- arready               <--- arready              <--- arready -+
<--- rdata                 <--- rdata
<--- rresp                 <--- rresp                <--- rdata   -+
<--- rvalid                <--- rvalid               <--- rresp    |
rready  --->       1       rready  --->      2       <--- rvalid   R
waddr   --->      ===>     awaddr  --->     ===>     rready  ---> -+
wdata   --->               awvalid ---> *
wmask   --->               <--- awready *            awaddr  ---> -+
wvalid  --->               wdata   --->              awvalid --->  AW
<--- wready                wmask   --->              <--- awready -+
<--- bresp                 wvalid  --->
<--- bvalid                <--- wready               wdata   ---> -+
bready  --->               <--- bresp                wstrb   --->  |
                           <--- bvalid               wvalid  --->  W
                           bready  --->              <--- wready  -+
                    
                                                     <--- bresp   -+
                                                     <--- bvalid   B
                                                     bready  ---> -+
```scala

这样我们就得到了AMBA AXI手册中的的AXI-Lite总线规范了!
AXI-Lite有5个事务通道, 分别是读地址(AR), 读数据(R), 写地址(AW), 写数据(W)和写回复(B),
它们的工作状态只取决与各自的握手信号, 因此它们可以独立工作,
例如读请求和写请求可以在同一个周期中同时发送.

在实际使用中, 我们还需要避免和握手信号相关的两种情况:
1. master和slave互相都在等待对方先将握手信号置1:
   master在等slave将`ready`置1后, 才将`valid`置1;
   而slave则在等master将`valid`置1后, 才将`ready`置1.
   结果就是双方无限制地等待, 造成[死锁(dead lock)][deadlock].
1. master和slave都在试探性地握手, 但试探失败后又都取消握手:
   * 在第1周期, master将`valid`置1, 但此时`ready`置0, 握手失败
   * 在第2周期, slave发现上一个周期master将`valid`置1, 因此这个周期将`ready`置1;
     但因为上一个周期握手失败, master在这个周期将`valid`置0, 于是这个周期握手仍然失败
   * 在第3周期, master发现上一个周期slave将`ready`置1, 因此这个周期将`valid`置1;
     但因为上一个周期握手失败, slave在这个周期将`ready`置0, 于是这个周期握手仍然失败
   * 结果双方仍然无限制地等待, 造成[活锁(live lock)][livelock].

[deadlock]: https://en.wikipedia.org/wiki/Deadlock
[livelock]: https://en.wikipedia.org/wiki/Deadlock#Livelock

```scala
        +---+   +---+   +---+   +---+
 clk    |   |   |   |   |   |   |   |
        +   +---+   +---+   +---+   +---+
        +-------+       +-------+
valid           |       |       |
                +-------+       +--------
                +-------+       +--------
ready           |       |       |
        +-------+       +-------+
```scala

> #### todo::避免握手的死锁和活锁
> 从微结构设计来看, 握手信号最重要的意义就是屏蔽通信双方的处理延迟.
> 你需要RTFM找到这些约束, 并正确理解它们.
>
> 注意你务必要查阅官方手册, 如果你参考了一些来源不够正规的资料,
> 你将会在接入SoC的时候陷入痛苦的调试黑洞.

### 让NPC支持AXI-Lite

至此, 你已经知道了AXI-Lite总线中的每一个信号因何加入, 并从需求角度理解了该总线规范的设计思想.
现在就可以把AXI-Lite加入到NPC中, 让NPC通过AXI-Lite来访问存储器了.

> #### todo::将IFU和LSU的访存接口改造成AXI-Lite
> 1. 将IFU和LSU的访存接口改造成AXI-Lite
> 1. 将IFU和LSU访问的SRAM模块用AXI-Lite进行封装, 但内部还是通过DPI-C来读写数据
>
> 由于IFU只会对存储器进行读操作, 不会写入存储器,
> 因此可以将IFU的`AW`, `W`和`B`三个通道的握手信号均置为0.
> 当然, 更好的做法是在握手信号的另一端通过`assert()`确保它们一直为0.
> 此外, 虽然目前SRAM模块的访问延迟还是固定的1周期,
> 但你需要在master和slave两端都正确地用握手来实现AXI-Lite总线协议.

<!-- -->
> #### caution::思考后消化的知识才是你真正掌握的
> 传统课本上对总线介绍通常只停留在协议层次, 并没有明确介绍如何从RTL层次实现总线,
> 因此如果大家只阅读课本, 总线仍然是一个相对抽象的概念.
> "一生一芯"是一个侧重动手实践的学习项目, 我们在讲义中已经给大家介绍了如何在RTL层次实现总线了.
>
> 不过, 如果你发现在实现的过程中还是存在一些难以克服的困难,
> 那就要给自己敲响警钟了: 你很可能缺乏将需求一步步转换为代码的能力.
> 你很可能需要反思你过去的学习方式, 例如:
> * 是否过分依赖框图, 导致你缺乏微结构设计能力, 在没有框图的情况下感觉无从下手
> * 更糟糕地, 是否过分依赖那些充满示例代码的资料和书籍,
>   导致你不仅缺乏微结构设计能力, 也缺乏将设计转换为代码的能力.
>   <font color=red>我们强烈不推荐初学者在自己的第一版代码能工作之前阅读这类资料和书籍!</font>
>
> 我们希望你可以把"独立思考"放在学习的首位, 而不是当代码的搬运工.
> 如果你发现从现在开始独立思考是一件很困难的事情,
> 很有可能是因为你在之前的学习中错过了太多, 使得你没有能力独自完成接下来的任务了.
> 如果真是这样, 我们建议你带着正确的心态重新开始学习"一生一芯".

事实上, 我们现在实现的AXI-Lite只是AXI的简化版,
完整的AXI总线规范有更多的信号和特性, 如果大家感兴趣, 也可以通过RTFM了解相关细节.
我们会在后续讲义中逐渐介绍更多我们需要使用的特性.

> #### caution::端正心态, 在迭代开发和调试中逐渐理解所有细节
> 不过, 作为一个业界中广泛使用的总线协议, AXI的细节还是不少,
> 导致大部分初学者其实很难在首次接触AXI的时候就可以理解得十分透彻.
> 因此, 大家也需要端正心态, "一次把总线代码全部写完, 以后就不用改"想法是不现实的.
>
> 事实上, 所有人都是在迭代开发和调试中逐渐理解总线的所有细节.
> 资深工程师学习新知识的时候尚且如此, 初学者想一步登天的想法并不符合学习的客观规律.

<!-- -->
> #### todo::测试总线的实现
> 为了避免上述问题, AXI标准规范对握手信号的行为添加了一些约束.
> 当然, 你可以按照从简单到复杂的顺序添加访存延迟:
> 1. 将SRAM的访问延迟依次修改成5, 10, 20等
> 1. 在SRAM模块中添加一个LSFR, 通过它来决定当前请求的延迟
> 1. 在IFU和LSU中也添加LSFR, 通过它来决定`AR`/`AW`/`W`通道中`valid`信号的延迟,
>    以及`R`/`B`通道中`ready`信号的延迟
>
> 在SRAM模块中添加随机延迟的功能, 来测试总线实现是否能在任意延迟下正确工作.

### 总线的仲裁

经过上述改动, 我们实例化了两个SRAM模块.
但在真实的硬件中, 这两个SRAM模块应该都对应到同一个存储器,
这一点目前是通过`pmem_read()`/`pmem_write()`访问仿真环境中唯一的存储器来实现的.
但在真实的硬件中不存在`pmem_read()`/`pmem_write()`这样的仿真环境功能,
因此需要考虑如何在硬件实现上让IFU和LSU访问同一个存储器.

这其实是一个多master的问题, 既然slave同时只能接收一个请求, 那就通过一个仲裁器(Arbiter)来决策:
当多个master同时访问同一个slave时, 获得访问权的master将得到放行, 可以成功访问slave;
其他master的请求将阻塞在仲裁器, 等待获得访问权的master访问结束后, 它们才能获得接下来的访问权.

简单整理一下, 仲裁器需要实现如下功能:
> 如果NPC在充满LSFR的随机延迟下仍然能正确启动RT-Thread, 就能大大增强你对代码的信心.
1. 调度: 选择一个正在发送有效请求的master

> #### todo::实现AXI-Lite仲裁器
> 保留一个AXI-Lite的SRAM模块, 编写一个AXI-Lite仲裁器, 从IFU和LSU中选择一个master与SRAM模块通信.
>
1. 阻塞: 阻塞其他master的访问
1. 转发: 将获得访问权的master的请求转发给slave, 并在slave的请求到达时, 将其转发给之前的master

多个master同时访问时具体如何选择, 其实是一个调度策略的问题.
在复杂系统中, 调度策略还需要考虑更多问题:

<!-- -->
> #### todo::评估NPC的主频和程序性能
> 实现了AXI-Lite之后, NPC就可以外接实际的SRAM了,
> 我们将要评估的对象是带有一个AXI-Lite接口的NPC, 其中包含刚才实现的AXI-Lite仲裁器,
> 而通过DPI-C实现的AXI-Lite接口的SRAM模块则不在评估范围内.
>
> 按照同样的评估方式, yzh另一个版本的NPC在`yosys-sta`项目默认提供的nangate45工艺下主频为297.711MHz,
> 因此可以算出microbench需要运行1.394s, 但仿真花费了29.861s.
首先要避免饥饿, 即任一个master都能在有限次仲裁后获得访问权;
> 虽然IPC下降了, 但因为主频大幅提升, 因此程序反而执行得更快了.
>
> 别忘了, 上面的单周期NPC评估结果是非常乐观的, 甚至是乐观到实际中不可行的程度.
其次还要避免死锁, 即仲裁器造成的阻塞不应使整个系统出现循环等待的现象.
不过目前NPC是一个多周期处理器, IFU和LSU的master不会同时发送请求,
> 接下来我们会接入SoC, 使得评估结果更接近流片场景.

<!-- -->
> #### caution::为什么要先实现总线?
> 过去有很多同学都对这个问题感到十分困惑, 甚至有同学认为这是讲义给大家挖的坑,
> 最大的原因是他们认为将来实现流水线的时候所有代码都需要推翻重写.
> 另一种声音是, 如果先写单周期, 后面也是要推翻重写.
>
> 之所以会让这些同学觉得后面需要推翻重写, 一方面有来自传统课本的原因:
> 传统课本确实把处理器的设计原理介绍得很清楚, 但却几乎不会考虑如何在不同微结构的处理器之间平滑过渡的问题,
> 毕竟这属于工程实践的范畴, 传统课本并不会将它作为一个知识点来讲解.
> 所以, 另一方面的原因就是这部分同学过分依赖传统课本:
> 他们仅仅按照课本上的内容去实现, 没有思考过如何采用合适的设计模式实现上述过渡.
>
> 对于初学者来说, 这其实不算一个大问题, 毕竟设计模式需要在充分了解各种细节之后才能进行抽象总结,
> 我们不应该要求初学者第一次学习就能思考出一个很好的设计模式.
> <font color=red>但如果你想学得更多, 就不应该把课本上的内容看作是处理器设计的全部,
> 不应该把推翻重写看作是浪费时间.</font>
> 作为还没有深入思考的初学者, 推翻重写的背后其实蕴含着极大的成长机会:
> 为什么前后两版设计的差别这么大? 能不能从中抽象总结出一些共性特征?
> 如果要重新来做这件事, 怎么样才能做得更好?
>
> 事实上, 好的经验和创新的机会都是从问题中总结出来的, 大家将来走向工作岗位,
> 肯定还会遇到更多不同的问题, 这些问题都不再像教科书那样有标准答案.
> 课本中的知识是有限的, 仅仅靠课本, 我们能成长的高度也是有限的,
> 但能够进一步帮助我们解决将来未知问题的是我们的思维习惯:
> 你在多次思考的过程中所形成的思维习惯, 要比课本中的知识重要得多.
>
> 回到处理器设计模式这个问题, 我们在2017年5月就已经思考并总结出相关经验,
> 并且在2017年和2018年南京大学参加的两届龙芯杯比赛,
> 以及2019年中国科学院大学发起的第一期"一生一芯"计划中都实践过, 并没有造成过多的推翻重写.
> 不少同学并不了解其中的情况, 因此也还是会根据自己的经验来下判断.
>
> 我们想说的是, 作为初学者, 你需要保持一颗好奇的心, 以及"绝知此事要躬行"的理念.
> 当别人跟你说这样你需要推翻重写时, 你不应该仅仅听从这些"忠告",
> <font color=green>而是应该思考为什么, 并通过自己的实践去钻研, 去回答这个问题</font>.
> 因为在学习当中, 你才是主角.

<!-- -->
> #### caution::所以为什么要先实现总线?
> 这是为了践行"先完成, 后完美"的设计法则.
>
> 如果我们把单周期处理器作为起点, 那流水线就应该属于"后完美"的部分.
> 因此, 我们先实现总线, 其实是先将处理器往可流片的方向靠拢, 实现"先完成",
> 即去掉任何一个功能, 要么处理器不能运行RT-Thread, 要么存储器和外设与可流片设计差别很大.
>
> 在"先完成"的基础上, 我们再通过量化评估方法理解每一种优化措施带来的性能收益.
> 这也是希望初学者将来可以量化地理解流水线设计对系统带来的性能提升,
> 而不仅仅是像传统课本那样, 将流水线设计作为一个将框图翻译成RTL代码的作业.
